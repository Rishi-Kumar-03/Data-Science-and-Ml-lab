{"cells":[{"cell_type":"code","source":["from sklearn.datasets import fetch_20newsgroups\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.linear_model import LogisticRegression\n","import numpy as np\n","import torch, torch.nn as nn, torch.optim as optim\n","\n","\n","# Load Data\n","\n","categories = ['comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware']\n","data = fetch_20newsgroups(subset='train', categories=categories, remove=('headers','footers','quotes'))\n","\n","vectorizer = CountVectorizer(binary=True, stop_words='english', max_features=5000)\n","X = vectorizer.fit_transform(data.data)\n","vocab = vectorizer.get_feature_names_out()\n","y_true = data.target   # only for evaluation\n","\n","\n","# Define Labeled Features\n","\n","labeled_features = {\n","    \"ibm\": 0,\n","    \"dos\": 0,\n","    \"apple\": 1,\n","    \"mac\": 1\n","}\n","lf_indices = {vectorizer.vocabulary_[w]: c for w,c in labeled_features.items() if w in vectorizer.vocabulary_}\n","\n","\n","# Baseline A: Feature Voting\n","\n","def feature_voting(X):\n","    preds = []\n","    for i in range(X.shape[0]):\n","        indices = X[i].nonzero()[1]\n","        votes = [lf_indices[j] for j in indices if j in lf_indices]\n","        if len(votes) == 0:\n","            preds.append(0)  # default to class 0\n","        else:\n","            preds.append(max(set(votes), key=votes.count))\n","    return np.array(preds)\n","\n","preds_voting = feature_voting(X)\n","acc_voting = (preds_voting == y_true).mean()\n","print(\"Baseline A (Feature Voting) Accuracy:\", acc_voting)\n","\n","\n","# Baseline B: Pseudo-Labeling + Logistic Regression\n","\n","pseudo_labels = []\n","pseudo_X = []\n","for i in range(X.shape[0]):\n","    indices = X[i].nonzero()[1]\n","    votes = [lf_indices[j] for j in indices if j in lf_indices]\n","    if len(votes) > 0:\n","        pseudo_labels.append(max(set(votes), key=votes.count))\n","        pseudo_X.append(X[i].toarray()[0])\n","\n","if len(pseudo_X) > 0:\n","    clf = LogisticRegression(max_iter=500)\n","    clf.fit(pseudo_X, pseudo_labels)\n","    preds_pseudo = clf.predict(X.toarray())\n","    acc_pseudo = (preds_pseudo == y_true).mean()\n","else:\n","    acc_pseudo = 0.0\n","\n","print(\"Baseline B (Pseudo-Labeling) Accuracy:\", acc_pseudo)\n","\n","\n","# GE-FL (Generalized Expectation)\n","num_classes = 2\n","num_features = X.shape[1]\n","X_tensor = torch.tensor(X.toarray(), dtype=torch.float32)\n","\n","W = nn.Parameter(torch.zeros(num_features, num_classes))\n","optimizer = optim.LBFGS([W], lr=0.1, max_iter=50)\n","\n","def model(X):\n","    logits = X @ W\n","    return torch.softmax(logits, dim=1)\n","\n","def ge_objective():\n","    probs = model(X_tensor)\n","    loss = torch.tensor(0.0)\n","    for idx, cls in lf_indices.items():\n","        mask = X_tensor[:, idx] > 0\n","        if mask.sum() == 0:\n","            continue\n","        dist = probs[mask].mean(0)\n","        ref = torch.ones(num_classes) * 0.1/(num_classes-1)\n","        ref[cls] = 0.9\n","        ref = ref / ref.sum()\n","        kl = torch.sum(ref * torch.log((ref + 1e-9)/(dist + 1e-9)))\n","        loss += kl\n","    loss += 0.5 * torch.sum(W**2)\n","    return loss\n","\n","def closure():\n","    optimizer.zero_grad()\n","    loss = ge_objective()\n","    loss.backward()\n","    return loss\n","\n","optimizer.step(closure)\n","\n","# Evaluate GE-FL\n","probs = model(X_tensor).detach().numpy()\n","preds_ge = probs.argmax(1)\n","acc_ge = (preds_ge == y_true).mean()\n","print(\"GE-FL Accuracy:\", acc_ge)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B507UcDHEClB","executionInfo":{"status":"ok","timestamp":1762672875368,"user_tz":-330,"elapsed":47858,"user":{"displayName":"durgaprasanth","userId":"08399602778327095816"}},"outputId":"4884c267-d9a2-4756-9956-08862eb56509"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Baseline A (Feature Voting) Accuracy: 0.690068493150685\n","Baseline B (Pseudo-Labeling) Accuracy: 0.6558219178082192\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/optim/lbfgs.py:457: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n","Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)\n","  loss = float(closure())\n"]},{"output_type":"stream","name":"stdout","text":["GE-FL Accuracy: 0.7842465753424658\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1X4SjfRDacKBllwmbvF7BWwAo3XaDOGrQ","timestamp":1757915579762},{"file_id":"/v2/external/notebooks/intro.ipynb","timestamp":1757313552305}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}